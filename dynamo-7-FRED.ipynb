{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical: building an economic statistics database\n",
    "\n",
    "The goal here is to have a bi-temporal database of interesting economic statistics (e.g. gross domestic product,\n",
    "consumer price index, U-6 employment rate.) With that, we can build models of the economy, interesting\n",
    "visualizations, etc.\n",
    "\n",
    "The source of the data with be FRED/ALFRED: the Federal Reserve of St. Louis's online db. This is the best\n",
    "government data resource I have ever seen: \n",
    "* their data is useful.\n",
    "* their APIs don't suck.\n",
    "* you send them mail, they respond with a useful answer (and sometimes, it is \"we will fix that.\")\n",
    "* every serious economics blog uses their charting, there is huge social benefit from the network effect.\n",
    "\n",
    "\n",
    "The plan is to query ALFRED for web data as needed, then store in our database in form that works nicely \n",
    "within our framework. I almost feel bad doing this because the source is so nice and so close to being bi-temporal\n",
    "that it would be almost reasonable to declare ALFRED a system-of-record in whatever we are building: making copies\n",
    "of the data seems to show somewhat of a lack of trust. But...\n",
    "\n",
    "1. I want my apps to run even if the internet is down.\n",
    "2. I want 100% report reproducibility even if ALFRED breaks a bi-temporal promise (by accident,\n",
    "funding constraints, a legal mandate, etc.)\n",
    "3. ALFRED timeseries data is bi-temporal, but the meta-data (e.g. categories) does not seem to be.\n",
    "4. Our bi-temporality is at the UTC microsecond level, ALFRED seems at the daily, naked date level. It's\n",
    "unclear how to even map between the two.\n",
    "5. It wouldn't be polite to hammer the Fed db with thousands of requests per second \n",
    "if we were running on a compute farm.\n",
    "\n",
    "\n",
    "So, in our space, bi-temporal time is just:\n",
    "* transaction - when we record our copy of some ALFRED data.\n",
    "* valid - either just a copy of physical, but maybe the ALFRED update time if we can understand and trust that.\n",
    "\n",
    "We may also add an additional time-line ('ALFRED') that supports transaction/valid dates in the ALFRED world.\n",
    "That way, for example, calls such as *consumerPriceIndex.value()* would behave in a FRED time-aware fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mand.core\n",
    "\n",
    "from mand.core import Entity, node, Context, _tr, ObjectDb\n",
    "from mand.core import displayDict, displayListOfDicts\n",
    "from mand.core import Monitor, PrintMonitor, SummaryMonitor\n",
    "from mand.lib.refdata import RefData\n",
    "\n",
    "db = ObjectDb(name='production-1', inMem=False, ro=False)\n",
    "\n",
    "pClock = _tr.Clock('RefData', db=db).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports for calling out to the FRED web-service.\n",
    "\n",
    "For those playing at home in the enterprise space, note that this notebook would now be auto-flagged as a data\n",
    "exfiltration risk point. But, mainly because the security meta-data system doesn't exist yet, \n",
    "just ignore this for now: a later workbook will cover this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "if sys.version_info[0] >= 3:\n",
    "    import urllib.request as url_request\n",
    "    import urllib.parse as url_parse\n",
    "    import urllib.error as url_error\n",
    "else:\n",
    "    import urllib2 as url_request\n",
    "    import urllib as url_parse\n",
    "    import urllib2 as url_error\n",
    "\n",
    "urlopen = url_request.urlopen\n",
    "quote_plus = url_parse.quote_plus\n",
    "urlencode = url_parse.urlencode\n",
    "HTTPError = url_error.HTTPError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A utility object for fetching FRED data [BA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FredManager at 0x10a7a7c90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FredManager(Entity):\n",
    "    # a hacked version of somebody (github:mortada?) else's code.\n",
    "    \n",
    "    max_results_per_request = 1000\n",
    "    \n",
    "    @node\n",
    "    def rootUrl(self):\n",
    "         return 'https://api.stlouisfed.org/fred'\n",
    "        \n",
    "    @node\n",
    "    def apiKeyFileName(self):\n",
    "        return '../fred/.api_key'\n",
    "    \n",
    "    @node\n",
    "    def apiKey(self):\n",
    "        key = os.environ.get('FRED_API_KEY')\n",
    "        if key:\n",
    "            return key\n",
    "        \n",
    "        api_key_file = self.apiKeyFileName()\n",
    "        f = open(api_key_file, 'r')\n",
    "        ret = f.readline().strip()\n",
    "        return ret\n",
    "    \n",
    "    def __fetch_data(self, url):\n",
    "        _url = url + '&api_key=' + self.apiKey()\n",
    "        try:\n",
    "            Monitor.msg('Web', 0, 'urlopen', value=url)\n",
    "            response = urlopen(_url)\n",
    "            root = ET.fromstring(response.read())\n",
    "        except HTTPError as exc:\n",
    "            root = ET.fromstring(exc.read())\n",
    "            raise ValueError(root.get('message'))\n",
    "        return root\n",
    "    \n",
    "    def __fetch_data_json(self, url):\n",
    "        _url = url\n",
    "        _url += '&api_key=' + self.apiKey()\n",
    "        _url += '&file_type=json'\n",
    "        try:\n",
    "            Monitor.msg('Web', 0, 'urlopen/json', value=url)\n",
    "            response = urlopen(_url)\n",
    "            r = response.read()\n",
    "        except HTTPError as exc:\n",
    "            root = ET.fromstring(exc.read())\n",
    "            raise ValueError(root.get('message'))\n",
    "        ret = json.loads(r)\n",
    "        return ret\n",
    "\n",
    "    \n",
    "    def get_series_info(self, series_id):\n",
    "        url = \"%s/series?series_id=%s\" % (self.rootUrl(), series_id)\n",
    "        root = self.__fetch_data(url)\n",
    "        info = root[0].attrib\n",
    "        return info\n",
    "    \n",
    "    def get_series_all_releases(self, series_id):\n",
    "        earliest_realtime_start = '1776-07-04'\n",
    "        latest_realtime_end = '9999-12-31'\n",
    "        f = \"%s/series/observations?series_id=%s&realtime_start=%s&realtime_end=%s\"\n",
    "        url =  f % (self.rootUrl(),\n",
    "                    series_id,\n",
    "                    earliest_realtime_start,\n",
    "                    latest_realtime_end)\n",
    "                                                                                        \n",
    "        root = self.__fetch_data(url)\n",
    "        data = [ child.attrib for child in root ]\n",
    "        return data\n",
    "\n",
    "    def search_category(self, category_id=0):\n",
    "        url = \"%s/category?category_id=%s&\" % (self.rootUrl(), category_id)\n",
    "        return self.__fetch_data_json(url)\n",
    "        \n",
    "    def search_category_children(self, category_id=0):\n",
    "        url = \"%s/category/children?category_id=%s&\" % (self.rootUrl(), category_id)\n",
    "        return self.__fetch_data_json(url)\n",
    "        \n",
    "    def __do_series_search(self, url):\n",
    "        root = self.__fetch_data(url)\n",
    "        num_results_total = int(root.get('count'))  # total number of results,\n",
    "                                                    # this can be larger than number of results returned\n",
    "        series_ids = [ child.get('id') for child in root ]\n",
    "        return series_ids, num_results_total\n",
    "    \n",
    "    def __get_search_results(self, url):\n",
    "        data, num_results_total = self.__do_series_search(url)\n",
    "        if data is None:\n",
    "            return data\n",
    "        max_results_needed = num_results_total\n",
    "        if max_results_needed > self.max_results_per_request:\n",
    "            for i in range(1, max_results_needed // self.max_results_per_request + 1):\n",
    "                offset = i * self.max_results_per_request\n",
    "                next_data, _ = self.__do_series_search(url + '&offset=' + str(offset))\n",
    "                data.append(next_data)\n",
    "        return data\n",
    "    \n",
    "    def search_by_category(self, category_id):\n",
    "        url = \"%s/category/series?category_id=%s&\" % (self.rootUrl(), category_id)\n",
    "        info = self.__get_search_results(url)\n",
    "        if info is None:\n",
    "            raise ValueError('No series exists for category id: ' + str(category_id))\n",
    "        return info\n",
    "    \n",
    "_tr.add(FredManager)\n",
    "_tr.FredManager('Main', db=db).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExternalRefData [Core]\n",
    "\n",
    "A simple reference data class.\n",
    "\n",
    "The **dataField** decorator does the real work:\n",
    "* It implements a standard bi-temporal stored node\n",
    "* Its method body implements the underlying fetching behavior (e.g. calling out to a website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mand.core import DBOMetaClass\n",
    "\n",
    "def dataField(f):\n",
    "    def fn(self):\n",
    "        return self.state().get(f.func_name)\n",
    "    fn._fetcher = f\n",
    "    fn.func_name = f.func_name\n",
    "    return fn # node(f)\n",
    "\n",
    "class ExternalRefDataMetaClass(DBOMetaClass):\n",
    "    def __new__(cls, name, parents, attrs):\n",
    "        ret = super(ExternalRefDataMetaClass, cls).__new__(cls, name, parents, attrs)\n",
    "        dataFields = []\n",
    "        for attrname, attrvalue in attrs.iteritems():\n",
    "            if getattr(attrvalue, '_fetcher', None):\n",
    "                dataFields.append(attrname)\n",
    "        ret._dataFields = dataFields\n",
    "        return ret\n",
    "\n",
    "class ExternalRefData(RefData):\n",
    "    __metaclass__ = ExternalRefDataMetaClass\n",
    "    \n",
    "    @node\n",
    "    def state(self):\n",
    "        ret = super(ExternalRefData, self).state()\n",
    "        # do something sensible for now if this is a new object:\n",
    "        if not ret:\n",
    "            ret = self._fetchData()\n",
    "        return ret\n",
    "    \n",
    "    def _fetchData(self):\n",
    "        data = {}\n",
    "        for name in self._dataFields:\n",
    "            data[name] = getattr(self, name)._fetcher(self)\n",
    "        return data\n",
    "    \n",
    "    def update(self):\n",
    "        data = self._fetchData()\n",
    "        super(ExternalRefData, self).update(**data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FredSeries [BA]\n",
    "\n",
    "An object that corresponds to a FRED time series. \n",
    "\n",
    "Note there is an implicit design pattern here: we store our copy of the external data with as little transformation\n",
    "as possible:\n",
    "* We don't try to parse dates\n",
    "* We don't try to parse floats\n",
    "* We don't check for missing values\n",
    "* We don't guess at what attributes to expect\n",
    "\n",
    "Our access routines will be reponsible for transforming the raw data into form useful to our consumers, because:\n",
    "* We have a better audit/debug world if we can look at the unmangled input data\n",
    "* We will have bugs in our transform logic, and it's much easier to fix code than to fix code and then re-import\n",
    "years of external data\n",
    "* We can always come back and write a cleverer importer once things are working. Except we never will, because this\n",
    "just isn't going to be a real system bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FredSeries(ExternalRefData):\n",
    "    @node \n",
    "    def fredManager(self):\n",
    "        return self.getObj(_tr.FredManager, 'Main')\n",
    "    \n",
    "    @node\n",
    "    def name(self):\n",
    "        return self.meta.name()\n",
    "    \n",
    "    @dataField\n",
    "    def info(self):\n",
    "        fm = self.fredManager()\n",
    "        return fm.get_series_info(self.name())\n",
    "    \n",
    "    @dataField\n",
    "    def allReleases(self):\n",
    "        fm = self.fredManager()\n",
    "        return fm.get_series_all_releases(self.name())\n",
    "        \n",
    "    @node\n",
    "    def data(self):\n",
    "        # In real life, we would depend on a custom date/date timestamp for observation visibility\n",
    "        import datetime\n",
    "        def parseDate(str):\n",
    "            return datetime.datetime.strptime(str, '%Y-%m-%d')\n",
    "        vis = {}\n",
    "        updated = {}\n",
    "        for record in self.allReleases():\n",
    "            value = record['value']\n",
    "            if value == '.':\n",
    "                continue\n",
    "            observationDate = parseDate(record['date'])\n",
    "            updateDate = parseDate(record['realtime_start'])\n",
    "            value = float(value)\n",
    "            if observationDate not in vis or updated[observationDate] < updateDate:\n",
    "                vis[observationDate] = value\n",
    "                updated[observationDate] = updateDate\n",
    "        return sorted(vis.items()) # that's so conservative it's virtually paranoid. \n",
    "                                   # I bet series is always in order.\n",
    "            \n",
    "    \"\"\"\n",
    "    ['observation_end', 'last_updated', 'observation_start', 'title', 'seasonal_adjustment_short', \n",
    "     'seasonal_adjustment', 'notes', 'popularity', 'realtime_end', 'frequency', 'units_short', \n",
    "     'units', 'realtime_start', 'id', 'frequency_short']\n",
    "    \"\"\"\n",
    "    \n",
    "_tr.add(FredSeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FredCategory [BA]\n",
    "\n",
    "A tree of refdata to manage the categorization of FRED timeseries.\n",
    "\n",
    "Note that, as always, we evaluate lazily: we won't fetch a part of the tree until someone asks for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FredCategory(ExternalRefData):\n",
    "    @node \n",
    "    def fredManager(self):\n",
    "        return self.getObj(_tr.FredManager, 'Main')\n",
    "    \n",
    "    @node\n",
    "    def id(self):\n",
    "        return self.meta.name()\n",
    "    \n",
    "    @dataField\n",
    "    def info(self):\n",
    "        fm = self.fredManager()\n",
    "        return fm.search_category(self.id())\n",
    "    \n",
    "    @dataField\n",
    "    def childCategoryInfo(self):\n",
    "        fm = self.fredManager()\n",
    "        ret = fm.search_category_children(self.id())\n",
    "        return ret.get('categories')\n",
    "      \n",
    "    @dataField\n",
    "    def seriesNames(self):\n",
    "        fm = self.fredManager()\n",
    "        return fm.search_by_category(self.id())\n",
    "    \n",
    "    @node\n",
    "    def name(self):\n",
    "        info = self.info()\n",
    "        return info['categories'][0]['name']\n",
    "    \n",
    "    @node\n",
    "    def childCategoryNames(self):\n",
    "       return [ c['id'] for c in self.childCategoryInfo() ] \n",
    "\n",
    "    @node\n",
    "    def children(self):\n",
    "       return self.getObjs(_tr.FredCategory, self.childCategoryNames())\n",
    "    \n",
    "    @node\n",
    "    def series(self):\n",
    "        return self.getObjs(_tr.FredSeries, self.seriesNames())\n",
    "    \n",
    "_tr.add(FredCategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get some data! [Test]\n",
    "\n",
    "Note that, if for some bizarre reason, you are actually trying to run this code at home, you will need to get\n",
    "an API key from the Fed. They are free, just apply at the FRED website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Web urlopen value: https://api.stlou...\n",
      "     Web urlopen value: https://api.stlou...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "|key|value|\n",
       "|-|-|\n",
       "|observation_end|2017-01-01\n",
       "|last_updated|2017-02-15 07:51:14-06\n",
       "|observation_start|1947-01-01\n",
       "|title|Consumer Price Index for All Urban Consumers: All Items\n",
       "|seasonal_adjustment_short|SA\n",
       "|seasonal_adjustment|Seasonally Adjusted\n",
       "|notes|The Consumer Price Index for All Urban Consumers: All Ite...\n",
       "|popularity|100\n",
       "|realtime_end|2017-03-14\n",
       "|frequency|Monthly\n",
       "|units_short|Index 1982-1984=100\n",
       "|units|Index 1982-1984=100\n",
       "|realtime_start|2017-03-14\n",
       "|id|CPIAUCSL\n",
       "|frequency_short|M"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with PrintMonitor(include='Web'):\n",
    "    with db:\n",
    "        cpi = FredSeries('CPIAUCSL')\n",
    "    \n",
    "    displayDict( cpi.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check... [Test]\n",
    "\n",
    "Once our data is cached in our local db, we shouldn't see any calls to the FRED website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with PrintMonitor(include='Web'):\n",
    "    gdp = FredSeries.get('GDP', db, create=True)\n",
    "    if not gdp.activeEvents():\n",
    "        gdp.update()\n",
    "    displayDict(gdp.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = gdp.allReleases()\n",
    "print len(r)\n",
    "displayListOfDicts(r[1000:1010])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "d = gdp.data()\n",
    "days, obs = zip(*d)\n",
    "plt.plot_date(x=days, y=obs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This seems true, if a little out of date:\n",
    "\n",
    "Get all data for a Fred series id including first releases and all revisions. \n",
    "This returns a DataFrame with three columns: 'date', 'realtime_start', and 'value'. \n",
    "For instance, the US GDP for Q4 2013 was first released to be 17102.5 on 2014-01-30, \n",
    "and then revised to 17080.7 on 2014-02-28, \n",
    "and then revised to 17089.6 on 2014-03-27. \n",
    "You will therefore get three rows with the same 'date' (observation date) of 2013-10-01 but three\n",
    "different 'realtime_start' of 2014-01-30, 2014-02-28, and 2014-03-27 \n",
    "with corresponding 'value' of 17102.5, 17080.7 and 17089.6\n",
    "\"\"\"\n",
    "\n",
    "d = '2013-10-01'\n",
    "t = [ i for i in r if i['date'] == d]\n",
    "displayListOfDicts(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with db:\n",
    "    fc = FredCategory('0')\n",
    "\n",
    "while True:\n",
    "    print\n",
    "    print fc.name()\n",
    "    if not fc.children():\n",
    "        break\n",
    "    displayListOfDicts(fc.childCategoryInfo())\n",
    "    fc = fc.children()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if fc.seriesNames():\n",
    "    for s in fc.series()[:5]:\n",
    "        displayDict( s.info())\n",
    "        print\n",
    "        print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
