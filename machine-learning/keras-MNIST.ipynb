{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelnaunton/anaconda/envs/py36-test/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/michaelnaunton/anaconda/envs/py36-test/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/michaelnaunton/anaconda/envs/py36-test/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "|Layer|Name|Unit|Activation|Size|iShape|oShape|nParam|nData|\n",
       "|-----|-----|----|----|------|------|------|-----|\n",
       "|1|conv2d_1|Conv2D|relu|(3, 3)|(28, 28, 1)|(26, 26, 32)|320|21632|\n",
       "|2|dropout_1|Dropout||0.6|(26, 26, 32)|(26, 26, 32)|0|21632|\n",
       "|3|conv2d_2|Conv2D|relu|(5, 5)|(26, 26, 32)|(22, 22, 32)|25632|15488|\n",
       "|4|dropout_2|Dropout||0.55|(22, 22, 32)|(22, 22, 32)|0|15488|\n",
       "|5|max_pooling2d_1|MaxPooling2D||(3, 3)|(22, 22, 32)|(10, 10, 32)|0|3200|\n",
       "|6|conv2d_3|Conv2D|relu|(5, 5)|(10, 10, 32)|(6, 6, 32)|25632|1152|\n",
       "|7|dropout_3|Dropout||0.4|(6, 6, 32)|(6, 6, 32)|0|1152|\n",
       "|8|flatten_1|Flatten|||(6, 6, 32)|(1152,)|0|1152|\n",
       "|9|dense_1|Dense|softmax||(1152,)|(10,)|11530|10|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63114\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.2952 - acc: 0.9052 - val_loss: 0.1290 - val_acc: 0.9797\n",
      "Epoch 2/60\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.0856 - acc: 0.9746 - val_loss: 0.0780 - val_acc: 0.9876\n",
      "Epoch 3/60\n",
      "60000/60000 [==============================] - 206s 3ms/step - loss: 0.0652 - acc: 0.9797 - val_loss: 0.0586 - val_acc: 0.9896\n",
      "Epoch 4/60\n",
      "60000/60000 [==============================] - 257s 4ms/step - loss: 0.0525 - acc: 0.9831 - val_loss: 0.0506 - val_acc: 0.9918\n",
      "Epoch 5/60\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.0476 - acc: 0.9849 - val_loss: 0.0516 - val_acc: 0.9926\n",
      "Epoch 6/60\n",
      "48768/60000 [=======================>......] - ETA: 20s - loss: 0.0413 - acc: 0.9861"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from utils import *\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3),\n",
    "                 input_shape=input_shape,\n",
    "                 activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(Dropout(0.55))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "prn(model)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24e 99.15 .5\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
